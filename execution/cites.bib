@inproceedings{lazyevaluator,
author = {Henderson, Peter and Morris, James H.},
title = {A Lazy Evaluator},
year = {1976},
isbn = {9781450374774},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800168.811543},
doi = {10.1145/800168.811543},
abstract = {A different way to execute pure LISP programs is presented. It delays the evaluation of parameters and list structures without ever having to perform more evaluation steps than the usual method. Although the central idea can be found in earlier work this paper is of interest since it treats a rather well-known language and works out an algorithm which avoids full substitution. A partial correctness proof using Scott-Strachey semantics is sketched in a later section.},
booktitle = {Proceedings of the 3rd ACM SIGACT-SIGPLAN Symposium on Principles on Programming Languages},
pages = {95–103},
numpages = {9},
location = {Atlanta, Georgia},
series = {POPL '76}
}

@InProceedings{futamura,
author="Futamura, Yoshihiko",
editor="Goto, Eiichi
and Furukawa, Koichi
and Nakajima, Reiji
and Nakata, Ikuo
and Yonezawa, Akinori",
title="Partial computation of programs",
booktitle="RIMS Symposia on Software Science and Engineering",
year="1983",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--35",
abstract="This paper attempts to clarify the difference between partial and ordinary computation. Partial computation of a computer program is by definition ``specializing a general program based upon its operating environment into a more efficient program''. It also shows the usefulness of partial computation. Finally, the formal theory of partial computation, technical problems in making it practical, and its future research problems are discussed.",
isbn="978-3-540-39442-6"
}

@InProceedings{10.1007/978-3-540-25937-4_24,
author="Rogaway, Phillip
and Shrimpton, Thomas",
editor="Roy, Bimal
and Meier, Willi",
title="Cryptographic Hash-Function Basics: Definitions, Implications, and Separations for Preimage Resistance, Second-Preimage Resistance, and Collision Resistance",
booktitle="Fast Software Encryption",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="371--388",
abstract="We consider basic notions of security for cryptographic hash functions: collision resistance, preimage resistance, and second-preimage resistance. We give seven different definitions that correspond to these three underlying ideas, and then we work out all of the implications and separations among these seven definitions within the concrete-security, provable-security framework. Because our results are concrete, we can show two types of implications, conventional and provisional, where the strength of the latter depends on the amount of compression achieved by the hash function. We also distinguish two types of separations, conditional and unconditional. When constructing counterexamples for our separations, we are careful to preserve specified hash-function domains and ranges; this rules out some pathological counterexamples and makes the separations more meaningful in practice. Four of our definitions are standard while three appear to be new; some of our relations and separations have appeared, others have not. Here we give a modern treatment that acts to catalog, in one place and with carefully-considered nomenclature, the most basic security notions for cryptographic hash functions.",
isbn="978-3-540-25937-4"
}

@Article{Klotz2013,
author={Klotz, Johannes Georg
and Bossert, Martin
and Schober, Steffen},
title={Computing preimages of Boolean networks},
journal={BMC Bioinformatics},
year={2013},
month={Aug},
day={12},
volume={14},
number={10},
pages={S4},
abstract={In this paper we present an algorithm based on the sum-product algorithm that finds elements in the preimage of a feed-forward Boolean networks given an output of the network. Our probabilistic method runs in linear time with respect to the number of nodes in the network. We evaluate our algorithm for randomly constructed Boolean networks and a regulatory network of Escherichia coli and found that it gives a valid solution in most cases.},
issn={1471-2105},
doi={10.1186/1471-2105-14-S10-S4},
url={https://doi.org/10.1186/1471-2105-14-S10-S4}
}

@article{akutsu2009analyses,
  title={Analyses and algorithms for predecessor and control problems for Boolean networks of bounded indegree},
  author={Akutsu, Tatsuya and Hayashida, Morihiro and Zhang, Shu-Qin and Ching, Wai-Ki and Ng, Michael K},
  journal={Information and Media Technologies},
  volume={4},
  number={2},
  pages={338--349},
  year={2009},
  publisher={Information and Media Technologies Editorial Board}
}

@ARTICLE{1353287,  author={Kwok, J.T.-Y. and Tsang, I.W.-H.},  journal={IEEE Transactions on Neural Networks},   title={The pre-image problem in kernel methods},   year={2004},  volume={15},  number={6},  pages={1517-1525},  doi={10.1109/TNN.2004.837781}}


@Article{sym13040586,
AUTHOR = {Barnett, Stephen M. and Jeffers, John and Pegg, David T.},
TITLE = {Quantum Retrodiction: Foundations and Controversies},
JOURNAL = {Symmetry},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {586},
URL = {https://www.mdpi.com/2073-8994/13/4/586},
ISSN = {2073-8994},
ABSTRACT = {Prediction is the making of statements, usually probabilistic, about future events based on current information. Retrodiction is the making of statements about past events based on current information. We present the foundations of quantum retrodiction and highlight its intimate connection with the Bayesian interpretation of probability. The close link with Bayesian methods enables us to explore controversies and misunderstandings about retrodiction that have appeared in the literature. To be clear, quantum retrodiction is universally applicable and draws its validity directly from conventional predictive quantum theory coupled with Bayes’ theorem.},
DOI = {10.3390/sym13040586}
}

@article{RevModPhys.27.179,
  title = {Symmetry of Physical Laws. {Part III}. Prediction and Retrodiction},
  author = {Watanabe, Satosi},
  journal = {Rev. Mod. Phys.},
  volume = {27},
  issue = {2},
  pages = {179--186},
  numpages = {0},
  year = {1955},
  month = {Apr},
  publisher = {American Physical Society},
  doi = {10.1103/RevModPhys.27.179},
  url = {https://link.aps.org/doi/10.1103/RevModPhys.27.179}
}

@Inbook{Aharonov2008,
author="Aharonov, Yakir
and Vaidman, Lev",
editor="Muga, J.G.
and Mayato, R. Sala
and Egusquiza, {\'I}.L.",
title="The Two-State Vector Formalism: An Updated Review",
bookTitle="Time in Quantum Mechanics",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="399--447",
isbn="978-3-540-73473-4",
doi="10.1007/978-3-540-73473-4_13",
url="https://doi.org/10.1007/978-3-540-73473-4_13"
}

@article{PhysRevA.54.147,
  title = {Quantum networks for elementary arithmetic operations},
  author = {Vedral, Vlatko and Barenco, Adriano and Ekert, Artur},
  journal = {Phys. Rev. A},
  volume = {54},
  issue = {1},
  pages = {147--153},
  numpages = {0},
  year = {1996},
  month = {Jul},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevA.54.147},
  url = {https://link.aps.org/doi/10.1103/PhysRevA.54.147}
}


@article{quteprints21763,
       publisher = {The University of Queensland Press},
          author = {Linda Burnett and William Millan and Edward Dawson and Andrew Clark},
            year = {2004},
           pages = {231--247},
         journal = {Australasian Journal of Combinatorics},
           title = {Simpler Methods for Generating Better Boolean Functions with Good Cryptographic Properties},
          volume = {29},
             url = {https://eprints.qut.edu.au/21763/}
}


@incollection{TOKAREVA20151,
title = {Chapter 1 - {Boolean} Functions},
editor = {Natalia Tokareva},
booktitle = {Bent Functions},
publisher = {Academic Press},
address = {Boston},
pages = {1-15},
year = {2015},
isbn = {978-0-12-802318-1},
doi = {https://doi.org/10.1016/B978-0-12-802318-1.00001-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128023181000017},
author = {Natalia Tokareva},
keywords = {Boolean function, Vectorial function, Algebraic normal form, Boolean cube, Hamming distance, Extended affine equivalence, Walsh-Hadamard transform, Finite field, Polynomial form, Trace form, Monomial function},
abstract = {In this chapter, we start with basic definitions related to Boolean functions. We consider the algebraic normal form of a Boolean function and the representation of a Boolean function over the Boolean cube. Extended affinely equivalent Boolean functions are defined as is the Walsh-Hadamard transform of a Boolean function. The finite field over F2 and its automorphisms are considered. It is shown how to associate Boolean functions in n variables with functions over the field F2n. We discuss polynomial representations of Boolean and vectorial Boolean functions. Representations of a Boolean function in the trace form and in the reduced trace form are given. Some details on the degree of a Boolean function in the trace form and on monomial functions are presented. The notions introduced in this chapter will be useful throughout the book.}
}

@inproceedings{10.1145/800027.808445,
author = {Boyer, Robert S. and Elspas, Bernard and Levitt, Karl N.},
title = {SELECT—a Formal System for Testing and Debugging Programs by Symbolic Execution},
year = {1975},
isbn = {9781450373852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800027.808445},
doi = {10.1145/800027.808445},
abstract = {SELECT is an experimental system for assisting in the formal systematic debugging of programs. It is intended to be a compromise between an automated program proving system and the current ad hoc debugging practice, and is similar to a system being developed by King et al. of IBM. SELECT systematically handles the paths of programs written in a LISP subset that includes arrays. For each execution path SELECT returns simplified conditions on input variables that cause the path to be executed, and simplified symbolic values for program variables at the path output. For conditions which form a system of linear equalities and inequalities SELECT will return input variable values that can serve as sample test data. The user can insert constraint conditions, at any point in the program including the output, in the form of symbolically executable assertions. These conditions can induce the system to select test data in user-specified regions. SELECT can also determine if the path is correct with respect to an output assertion. We present four examples demonstrating the various modes of system operation and their effectiveness in finding bugs. In some examples, SELECT was successful in automatically finding useful test data. In others, user interaction was required in the form of output assertions. SELECT appears to be a useful tool for rapidly revealing program errors, but for the future there is a need to expand its expressive and deductive power.},
booktitle = {Proceedings of the International Conference on Reliable Software},
pages = {234–245},
numpages = {12},
keywords = {Solution of systems of inequalities, Program debugging, Symbolic execution, Program testing, Program verification, Test data generation},
location = {Los Angeles, California}
}

@article{10.1145/390016.808445,
author = {Boyer, Robert S. and Elspas, Bernard and Levitt, Karl N.},
title = {SELECT—a Formal System for Testing and Debugging Programs by Symbolic Execution},
year = {1975},
issue_date = {June 1975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/390016.808445},
doi = {10.1145/390016.808445},
abstract = {SELECT is an experimental system for assisting in the formal systematic debugging of programs. It is intended to be a compromise between an automated program proving system and the current ad hoc debugging practice, and is similar to a system being developed by King et al. of IBM. SELECT systematically handles the paths of programs written in a LISP subset that includes arrays. For each execution path SELECT returns simplified conditions on input variables that cause the path to be executed, and simplified symbolic values for program variables at the path output. For conditions which form a system of linear equalities and inequalities SELECT will return input variable values that can serve as sample test data. The user can insert constraint conditions, at any point in the program including the output, in the form of symbolically executable assertions. These conditions can induce the system to select test data in user-specified regions. SELECT can also determine if the path is correct with respect to an output assertion. We present four examples demonstrating the various modes of system operation and their effectiveness in finding bugs. In some examples, SELECT was successful in automatically finding useful test data. In others, user interaction was required in the form of output assertions. SELECT appears to be a useful tool for rapidly revealing program errors, but for the future there is a need to expand its expressive and deductive power.},
journal = {SIGPLAN Not.},
month = {apr},
pages = {234–245},
numpages = {12},
keywords = {Program debugging, Program verification, Test data generation, Symbolic execution, Program testing, Solution of systems of inequalities}
}


@article{10.1145/360248.360252,
author = {King, James C.},
title = {Symbolic Execution and Program Testing},
year = {1976},
issue_date = {July 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {7},
issn = {0001-0782},
url = {https://doi.org/10.1145/360248.360252},
doi = {10.1145/360248.360252},
abstract = {This paper describes the symbolic execution of programs. Instead of supplying the normal inputs to a program (e.g. numbers) one supplies symbols representing arbitrary values. The execution proceeds as in a normal execution except that values may be symbolic formulas over the input symbols. The difficult, yet interesting issues arise during the symbolic execution of conditional branch type statements. A particular system called EFFIGY which provides symbolic execution for program testing and debugging is also described. It interpretively executes programs written in a simple PL/I style programming language. It includes many standard debugging features, the ability to manage and to prove things about symbolic expressions, a simple program testing manager, and a program verifier. A brief discussion of the relationship between symbolic execution and program proving is also included.},
journal = {Commun. ACM},
month = {jul},
pages = {385–394},
numpages = {10},
keywords = {symbolic execution, program proving, symbolic interpretation, program verification, program testing, program debugging}
}

@InProceedings{howden,
  author = 	 {William E. Howden},
  title = 	 {Experiments with a symbolic evaluation system},
  booktitle = {Proceedings of the National Computer Conference},
  year = 	 1976}

@inproceedings{10.1145/800191.805647,
author = {Clarke, Lori A.},
title = {A Program Testing System},
year = {1976},
isbn = {9781450374897},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800191.805647},
doi = {10.1145/800191.805647},
abstract = {A system that aids in testing programs is described. This system symbolically executes program paths and creates symbolic representations of the output variables that aid in verifying a path's computations. The conditional statements that affect the flow of control are also symbolically represented by a set of inequalities. The inequalities are then evaluated to determine input data that would cause execution of the path. The system also does extensive error checking by simulating possible data dependent errors and then attempting to detect data sets that would cause execution errors.},
booktitle = {Proceedings of the 1976 Annual Conference},
pages = {488–491},
numpages = {4},
location = {Houston, Texas, USA},
series = {ACM '76}
}

@article{10.1145/3182657,
author = {Baldoni, Roberto and Coppa, Emilio and D’elia, Daniele Cono and Demetrescu, Camil and Finocchi, Irene},
title = {A Survey of Symbolic Execution Techniques},
year = {2018},
issue_date = {May 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3182657},
doi = {10.1145/3182657},
abstract = {Many security and software testing applications require checking whether certain properties of a program hold for any possible usage scenario. For instance, a tool for identifying software vulnerabilities may need to rule out the existence of any backdoor to bypass a program’s authentication. One approach would be to test the program using different, possibly random inputs. As the backdoor may only be hit for very specific program workloads, automated exploration of the space of possible inputs is of the essence. Symbolic execution provides an elegant solution to the problem, by systematically exploring many possible execution paths at the same time without necessarily requiring concrete inputs. Rather than taking on fully specified input values, the technique abstractly represents them as symbols, resorting to constraint solvers to construct actual instances that would cause property violations. Symbolic execution has been incubated in dozens of tools developed over the past four decades, leading to major practical breakthroughs in a number of prominent software reliability applications. The goal of this survey is to provide an overview of the main ideas, challenges, and solutions developed in the area, distilling them for a broad audience.},
journal = {ACM Comput. Surv.},
month = {may},
articleno = {50},
numpages = {39},
keywords = {static analysis, software testing, Symbolic execution, concolic execution}
}

@Article{djdeq,
  author = 	 {Alastair A. Abbott},
  title = 	 {The {Deutsch-Jozsa} problem: de-quantization and entanglement},
  journal = 	 {Natural Computing},
  year = 	 2012,
  volume = 	 11}


@article{10.2307/3560059,
 ISSN = {13645021},
 URL = {http://www.jstor.org/stable/3560059},
 abstract = {For any quantum algorithm operating on pure states, we prove that the presence of multi-partite entanglement, with a number of parties that increases unboundedly with input size, is necessary if the quantum algorithm is to offer an exponential speed-up over classical computation. Furthermore, we prove that the algorithm can be efficiently simulated classically to within a prescribed tolerance η even if a suitably small amount of global entanglement is present. We explicitly identify the occurrence of increasing multi-partite entanglement in Shor's algorithm. Our results do not apply to quantum algorithms operating on mixed states in general and we discuss the suggestion that an exponential computational speed-up might be possible with mixed states in the total absence of entanglement. Finally, despite the essential role of entanglement for pure-state algorithms, we argue that it is nevertheless misleading to view entanglement as a key resource for quantum-computational power.},
 author = {Richarda Jozsa and Noah Linden},
 journal = {Proceedings: Mathematical, Physical and Engineering Sciences},
 number = {2036},
 pages = {2011--2032},
 publisher = {The Royal Society},
 title = {On the Role of Entanglement in Quantum-Computational Speed-Up},
 volume = {459},
 year = {2003}
}


@article{10.1145/3341106,
author = {Komargodski, Ilan and Naor, Moni and Yogev, Eylon},
title = {White-Box vs. Black-Box Complexity of Search Problems: Ramsey and Graph Property Testing},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {66},
number = {5},
issn = {0004-5411},
url = {https://doi.org/10.1145/3341106},
doi = {10.1145/3341106},
abstract = {Ramsey theory assures us that in any graph there is a clique or independent set of a certain size, roughly logarithmic in the graph size. But how difficult is it to find the clique or independent set? If the graph is given explicitly, then it is possible to do so while examining a linear number of edges. If the graph is given by a black-box, where to figure out whether a certain edge exists the box should be queried, then a large number of queries must be issued. But what if one is given a program or circuit for computing the existence of an edge? This problem was raised by Buss and Goldberg and Papadimitriou in the context of TFNP, search problems with a guaranteed solution.We examine the relationship between black-box complexity and white-box complexity for search problems with guaranteed solution such as the above Ramsey problem. We show that under the assumption that collision-resistant hash function exists (which follows from the hardness of problems such as factoring, discrete-log, and learning with errors) the white-box Ramsey problem is hard and this is true even if one is looking for a much smaller clique or independent set than the theorem guarantees. This is also true for the colorful Ramsey problem where one is looking, say, for a monochromatic triangle.In general, one cannot hope to translate all black-box hardness for TFNP into white-box hardness: we show this by adapting results concerning the random oracle methodology and the impossibility of instantiating it.Another model we consider is that of succinct black-box, where the complexity of an algorithm is measured as a function of the description size of the object in the box (and no limitation on the computation time). In this case, we show that for all TFNP problems there is an efficient algorithm with complexity proportional to the description size of the object in the box times the solution size. However, for promise problems this is not the case.Finally, we consider the complexity of graph property testing in the white-box model. We show a property that is hard to test even when one is given the program for computing the graph (under the appropriate assumptions such as hardness of Decisional Diffie-Hellman). The hard property is whether the graph is a two-source extractor.},
journal = {J. ACM},
month = {jul},
articleno = {34},
numpages = {28},
keywords = {black-box hardness, Ramsey theory, white-box hardness}
}

@inproceedings{10.1145/800157.805047,
author = {Cook, Stephen A.},
title = {The Complexity of Theorem-Proving Procedures},
year = {1971},
isbn = {9781450374644},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800157.805047},
doi = {10.1145/800157.805047},
abstract = {It is shown that any recognition problem solved by a polynomial time-bounded nondeterministic Turing machine can be “reduced” to the problem of determining whether a given propositional formula is a tautology. Here “reduced” means, roughly speaking, that the first problem can be solved deterministically in polynomial time provided an oracle is available for solving the second. From this notion of reducible, polynomial degrees of difficulty are defined, and it is shown that the problem of determining tautologyhood has the same polynomial degree as the problem of determining whether the first of two given graphs is isomorphic to a subgraph of the second. Other examples are discussed. A method of measuring the complexity of proof procedures for the predicate calculus is introduced and discussed.},
booktitle = {Proceedings of the Third Annual ACM Symposium on Theory of Computing},
pages = {151–158},
numpages = {8},
location = {Shaker Heights, Ohio, USA},
series = {STOC '71}
}

@Inbook{Karp1972,
author="Karp, Richard M.",
editor="Miller, Raymond E.
and Thatcher, James W.
and Bohlinger, Jean D.",
title="Reducibility among Combinatorial Problems",
bookTitle="Complexity of Computer Computations: Proceedings of a symposium on the Complexity of Computer Computations, held March 20--22, 1972, at the IBM Thomas J. Watson Research Center, Yorktown Heights, New York, and sponsored by the Office of Naval Research, Mathematics Program, IBM World Trade Corporation, and the IBM Research Mathematical Sciences Department",
year="1972",
publisher="Springer US",
address="Boston, MA",
pages="85--103",
abstract="A large class of computational problems involve the determination of properties of graphs, digraphs, integers, arrays of integers, finite families of finite sets, boolean formulas and elements of other countable domains. Through simple encodings from such domains into the set of words over a finite alphabet these problems can be converted into language recognition problems, and we can inquire into their computational complexity. It is reasonable to consider such a problem satisfactorily solved when an algorithm for its solution is found which terminates within a number of steps bounded by a polynomial in the length of the input. We show that a large number of classic unsolved problems of covering, matching, packing, routing, assignment and sequencing are equivalent, in the sense that either each of them possesses a polynomial-bounded algorithm or none of them does.",
isbn="978-1-4684-2001-2",
doi="10.1007/978-1-4684-2001-2_9",
url="https://doi.org/10.1007/978-1-4684-2001-2_9"
}

@ARTICLE{4640789,  author={Trakhtenbrot, B.A.},  journal={Annals of the History of Computing},   title={A Survey of Russian Approaches to Perebor (Brute-Force Searches) Algorithms},   year={1984},  volume={6},  number={4},  pages={384-400},  doi={10.1109/MAHC.1984.10036}}

@book{nielsen_chuang_2010, place={Cambridge}, title={Quantum Computation and Quantum Information: 10th Anniversary Edition}, DOI={10.1017/CBO9780511976667}, publisher={Cambridge University Press}, author={Nielsen, Michael A. and Chuang, Isaac L.}, year={2010}}


@article{doi:10.1137/S0097539795293172,
author = {Shor, Peter W.},
title = {Polynomial-Time Algorithms for Prime Factorization and Discrete Logarithms on a Quantum Computer},
journal = {SIAM Journal on Computing},
volume = {26},
number = {5},
pages = {1484-1509},
year = {1997},
doi = {10.1137/S0097539795293172},

URL = { 
        https://doi.org/10.1137/S0097539795293172
    
},
eprint = { 
        https://doi.org/10.1137/S0097539795293172
    
}
,
    abstract = { A digital computer is generally believed to be an efficient universal computing device; that is, it is believed able to simulate any physical computing device with an increase in computation time by at most a polynomial factor. This may not be true when quantum mechanics is taken into consideration. This paper considers factoring integers and finding discrete logarithms, two problems which are generally thought to be hard on a classical computer and which have been used as the basis of several proposed cryptosystems. Efficient randomized algorithms are given for these two problems on a hypothetical quantum computer. These algorithms take a number of steps polynomial in the input size, e.g., the number of digits of the integer to be factored. }
}


@inproceedings{10.1145/237814.237866,
author = {Grover, Lov K.},
title = {A Fast Quantum Mechanical Algorithm for Database Search},
year = {1996},
isbn = {0897917855},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/237814.237866},
doi = {10.1145/237814.237866},
booktitle = {Proceedings of the Twenty-Eighth Annual ACM Symposium on Theory of Computing},
pages = {212–219},
numpages = {8},
location = {Philadelphia, Pennsylvania, USA},
series = {STOC '96}
}


@INPROCEEDINGS{365701,  author={Simon, D.R.},  booktitle={Proceedings 35th Annual Symposium on Foundations of Computer Science},   title={On the power of quantum computation},   year={1994},  volume={},  number={},  pages={116-123},  doi={10.1109/SFCS.1994.365701}}


@Article{deutsch,
  author = 	 {David Deutsch},
  title = 	 {Quantum theory, the Church–Turing principle and the universal quantum computer},
  journal = 	 {Proc. R. Soc. Lond. A 400},
  year = 	 1985}

@Article{deutschJozsa,
  author = 	 {David Deutsch and Richard Jozsa},
  title = 	 {Rapid solution of problems by quantum computation},
  journal = 	 {Proc. R. Soc. Lond. A 439},
  year = 	 1992}


@article{doi:10.1137/S0097539796300921,
author = {Bernstein, Ethan and Vazirani, Umesh},
title = {Quantum Complexity Theory},
journal = {SIAM Journal on Computing},
volume = {26},
number = {5},
pages = {1411-1473},
year = {1997},
doi = {10.1137/S0097539796300921},

URL = { 
        https://doi.org/10.1137/S0097539796300921
    
},
eprint = { 
        https://doi.org/10.1137/S0097539796300921
    
}
,
    abstract = { In this paper we study quantum computation from a complexity theoretic viewpoint. Our first result is the existence of an efficient universal quantum Turing machine in Deutsch's model of a quantum Turing machine (QTM) [Proc. Roy. Soc. London Ser. A, 400 (1985), pp. 97--117]. This construction is substantially more complicated than the corresponding construction for classical Turing machines (TMs); in fact, even simple primitives such as looping, branching, and composition are not straightforward in the context of quantum Turing machines. We establish how these familiar primitives can be implemented and introduce some new, purely quantum mechanical primitives, such as changing the computational basis and carrying out an arbitrary unitary transformation of polynomially bounded dimension.We also consider the precision to which the transition amplitudes of a quantum Turing machine need to be specified. We prove that \$O(\log T)\$ bits of precision suffice to support a T step computation. This justifies the claim that the quantum Turing machine model should be regarded as a discrete model of computation and not an analog one. We give the first formal evidence that quantum Turing machines violate the modern (complexity theoretic) formulation of the Church--Turing thesis. We show the existence of a problem, relative to an oracle, that can be solved in polynomial time on a quantum Turing machine, but requires superpolynomial time on a bounded-error probabilistic Turing machine, and thus not in the class \$\BPP\$. The class \$\BQP\$ of languages that are efficiently decidable (with small error-probability) on a quantum Turing machine satisfies \$\BPP \subseteq \BQP \subseteq \Ptime^{\SP}\$. Therefore, there is no possibility of giving a mathematical proof that quantum Turing machines are more powerful than classical probabilistic Turing machines (in the unrelativized setting) unless there is a major breakthrough in complexity theory. }
}


@Article{shorFermat,
  author = 	 {Geller, Michael R. and Zhou, Zhongyuan},
  title = 	 {Factoring 51 and 85 with 8 qubits},
  journal = 	 {Scientific Reports (3023)},
  year = 	 2013,
  volume = 	 3,
  number = 	 1}

